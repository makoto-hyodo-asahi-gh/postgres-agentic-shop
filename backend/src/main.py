import warnings
from contextlib import asynccontextmanager

from fastapi import FastAPI
from fastapi.openapi.utils import get_openapi
from fastapi.staticfiles import StaticFiles
from openinference.instrumentation.llama_index import LlamaIndexInstrumentor
from pgvector.asyncpg import register_vector
from phoenix.otel import register
from src.config.config import settings
from src.config.embed_model import EmbedModelManager
from src.config.llm import LLMManager
from src.config.vector_store import VectorStoreManager
from src.database import engine
from src.logger import logger
from src.middleware.user_middleware import add_user_id_to_request
from src.routes import agents, products, reset, reviews, users
from starlette.responses import FileResponse


class CachedStaticFiles(StaticFiles):
    async def get_response(self, path: str, scope):
        full_path, stat_result = self.lookup_path(path)
        if stat_result is None:
            return self.not_found_response(path)
        return FileResponse(
            full_path,
            stat_result=stat_result,
            headers={"Cache-Control": "public, max-age=31536000, immutable"},
        )


# Filter pydantic warnings generated by llama_index modules
warnings.filterwarnings(
    "ignore",
    category=DeprecationWarning,
    module=r".*llama_index.*",
)


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Initialize singleton dependencies at app startup and clean them up on shutdown."""

    async with engine.begin() as conn:
        raw_connection = await conn.get_raw_connection()
        asyncpg_conn = raw_connection.driver_connection
        await register_vector(asyncpg_conn)
        logger.info("pgvector extension registered successfully")

    # Create global instances
    app.state.vector_store_products_embeddings = (
        await VectorStoreManager.get_vector_store(
            db_embedding_table_name=settings.DB_EMBEDDING_TABLE_FOR_PRODUCTS,
        )
    )
    app.state.vector_store_reviews_embeddings = (
        await VectorStoreManager.get_vector_store(
            db_embedding_table_name=settings.DB_EMBEDDING_TABLE_FOR_REVIEWS,
        )
    )
    app.state.llm = await LLMManager.get_llm()
    app.state.embed_model = await EmbedModelManager.get_embed_model()

    tracer_provider = register(
        project_name=settings.PHOENIX_PROJECT_NAME,
        endpoint=settings.PHOENIX_COLLECTOR_ENDPOINT,
        # batch=True,  # Use BatchSpanProcessor for better performance
        verbose=True,
        auto_instrument=True,
    )

    LlamaIndexInstrumentor().instrument(
        skip_dep_check=True,
        tracer_provider=tracer_provider,
    )

    yield  # App runs

    app.state.vector_store_products_embeddings = None
    app.state.vector_store_reviews_embeddings = None
    app.state.llm = None
    app.state.embed_model = None


def custom_openapi():
    """
    Generates a custom OpenAPI schema for the FastAPI application.

    If the schema is already generated and cached in `app.openapi_schema`, it returns that.
    Otherwise, it generates a new schema using FastAPI's `get_openapi`, adds a custom header
    (`X-User-Id`) as a required parameter to all endpoints, and stores it back in
    `app.openapi_schema` for reuse.

    The custom header is useful for emulating user session.
    """
    if app.openapi_schema:
        return app.openapi_schema
    openapi_schema = get_openapi(
        title=app.title,
        version=app.version,
        description=app.description,
        routes=app.routes,
    )
    # Define the custom header
    custom_header = {
        "name": "X-User-Id",
        "in": "header",
        "required": True,
        "description": "Simulates a user session by passing a user ID in the header.",
        "schema": {"type": "integer"},
    }
    # Add the custom header to all paths
    for path in openapi_schema["paths"].values():
        for method in path:
            path[method].setdefault("parameters", [])
            path[method]["parameters"].append(custom_header)
    app.openapi_schema = openapi_schema
    return app.openapi_schema


app = FastAPI(
    title="AI Retail Solution Accelerator",
    description="Provides APIs for AI Retail Solution Accelerator",
    version=settings.APP_VERSION,
    lifespan=lifespan,
)

app.openapi = custom_openapi
app.middleware("http")(add_user_id_to_request)
app.include_router(products.router, prefix="/api/v1")
app.include_router(reviews.router, prefix="/api/v1")
app.include_router(agents.router, prefix="/api/v1")
app.include_router(users.router, prefix="/api/v1")
app.include_router(reset.router, prefix="/api/v1")


app.mount("/data", CachedStaticFiles(directory="data/"), name="data")
